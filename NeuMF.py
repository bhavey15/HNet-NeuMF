# -*- coding: utf-8 -*-
"""CF_Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nG2HB7PAcJ_Yl0X-l59n6DG3tg45RZoh
"""

!pip install implicit
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import implicit
from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics
import scipy.sparse as sparse
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from sklearn.metrics import accuracy_score,precision_recall_curve,roc_curve, auc, f1_score, roc_auc_score, precision_score, recall_score

"""##**C Dataset**"""

#Disease Features from heterogeneous network
dis_features = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/disease_feature.txt', header=None)
dis_features = dis_features.iloc[:,1:].values
dis_features.shape

#Drug Features from heterogeneous network
drug_features = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/drug_feature.txt', header=None)
drug_features = drug_features.iloc[:,1:].values
drug_features.shape

#Drug Disease Association Matrix
dda_mat = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/DiDrAMat.txt', sep = ' ', header=None)
dda_mat = dda_mat.values
dda_mat.shape

#Getting the train, validation and test datasets.
train = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/train.txt', sep=' ',header=None)
# drug_features = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/drug_feature.txt', header=None)
val = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/valid.txt', sep=' ',header=None)
test = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/test.txt', sep=' ',header=None)
final_data = pd.concat([train,val],ignore_index=True, sort=False)
# train.head(),val.head(),test.head()
final_data.head(),final_data.shape

#Drug and Disease Features corresponding to their IDs
drug_f = dict()
with open('/content/drive/MyDrive/CF Dataset/CDataset/drug_feature.txt', 'r') as f:
    for line in f:
        drug_id, fp = line.strip().split()
        fp = np.array(fp.split(','), dtype='float32')
        drug_f[drug_id] = fp

disease_f = dict()
with open('/content/drive/MyDrive/CF Dataset/CDataset/disease_feature.txt', 'r') as f:
    for line in f:
        disease_id, md = line.strip().split()
        md = np.array(md.split(','), dtype='float32')
        disease_f[disease_id] = md

#Giving a code to every drug and disease
drug_code={}
dis_code={}
i=0
for drug in drug_f.keys():
  drug_code[drug]=i
  i+=1
i=0
for dis in disease_f.keys():
  dis_code[dis]=i
  i+=1

#10 Fold CV
from sklearn.model_selection import KFold
kf = KFold(n_splits=10)

n_drugs = np.unique(train.iloc[:,0].values).shape[0]
n_dis = np.unique(train.iloc[:,1].values).shape[0]
print(n_drugs, n_dis)
def get_data(data):
  """
  Function that returns all 4 components of data
  """
  train_drug = np.array([drug_code[d] for d in data.iloc[:,0].values])
  train_dis = np.array([dis_code[d] for d in data.iloc[:,1].values])
  train_drug_features = np.array([drug_f[d] for d in data.iloc[:,0].values])
  train_dis_features = np.array([disease_f[d] for d in data.iloc[:,1].values])
  return train_drug, train_dis, train_drug_features, train_dis_features
train_drug, train_dis, train_drug_features, train_dis_features = get_data(train)

#Generalized Matrix Factorization
import torch
# define the class of GMF model
class GMF(torch.nn.Module):
    def __init__(self, n_drugs,n_dis,latent_dim=100):
        super(GMF, self).__init__()
        self.embedding_drug = torch.nn.Embedding(num_embeddings=n_drugs, embedding_dim=latent_dim)
        self.embedding_dis = torch.nn.Embedding(num_embeddings=n_dis, embedding_dim=latent_dim)
        # add the user and item bias
        self.drug_bias = nn.Embedding(n_drugs, 1)
        self.dis_bias = nn.Embedding(n_dis, 1)
        #uniform the embedding of user and item 
        self.embedding_drug.weight.data.uniform_(0,0.05)
        self.embedding_dis.weight.data.uniform_(0,0.05)
        self.drug_bias.weight.data.uniform_(-0.01,0.01)
        self.dis_bias.weight.data.uniform_(-0.01,0.01)
        self.affine_output = torch.nn.Linear(in_features=latent_dim, out_features=1)
        # set sigmoid function
        self.logistic = torch.nn.Sigmoid()


    def forward(self, user_indices, item_indices):
        drug_embedding = self.embedding_drug(user_indices)
        dis_embedding = self.embedding_dis(item_indices)
        dis_bias_mf = self.dis_bias(item_indices)
        drug_bias_mf = self.drug_bias(user_indices)
        element_product = torch.mul(drug_embedding, dis_embedding)
        element_product = element_product + dis_bias_mf+drug_bias_mf
        logits = self.affine_output(element_product)
        rating = self.logistic(logits)
        # rating = logits
        return rating

def train_epocs_gmf(model, epochs=10, lr=1e-3, wd=0.0, unsqueeze=False):
    loss_arr=[]
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    model.train()
    for i in range(epochs):
        # users = torch.LongTensor(train.iloc[:,0].values)#.cuda()
        # items = torch.LongTensor(train.iloc[:,1].values)#.cuda()
        users = torch.LongTensor(train_drug)
        items = torch.LongTensor(train_dis)
        ratings = torch.FloatTensor(train.iloc[:,2].values)#.cuda()
        if unsqueeze:
            ratings = ratings.unsqueeze(1)
        y_hat = model(users, items)
        loss = F.mse_loss(y_hat, ratings)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        print(loss.item()) 
        loss_arr.append(loss.item())
    # test_loss(model, unsqueeze)
    print('save')
    # save the weight of model
    torch.save(model.state_dict(), 'gmf_model.pt')
    plt.plot(loss_arr)
    plt.xlabel('epochs')
    plt.ylabel('MSE loss')
    plt.title('GMF')
    plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'GMF_MSE_Loss.png')

gmf_model = GMF(n_drugs, n_dis)
train_epocs_gmf(gmf_model, epochs=100, lr=0.01, wd=1e-6, unsqueeze=True)

#Multi Layer Perceptron Model
class MLP(torch.nn.Module):
    def __init__(self, n_drugs,n_dis,latent_dim=32,layers=[64,32,16,8]):
        super(MLP, self).__init__()
        self.feature_size = train_dis_features.shape[1]
        self.embedding_drug = torch.nn.Linear(self.feature_size, latent_dim)
        self.embedding_dis = torch.nn.Linear(self.feature_size, latent_dim)
        self.drug_bias = nn.Embedding(n_drugs, 1)
        self.dis_bias = nn.Embedding(n_dis, 1)
        self.embedding_drug.weight.data.uniform_(0,0.05)
        self.embedding_dis.weight.data.uniform_(0,0.05)
        self.drug_bias.weight.data.uniform_(-0.01,0.01)
        self.dis_bias.weight.data.uniform_(-0.01,0.01)

        self.fc_layers = torch.nn.ModuleList()
        for idx, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):
            self.fc_layers.append(torch.nn.Linear(in_size, out_size))
        self.affine_output = torch.nn.Linear(in_features=layers[-1], out_features=1)
        self.logistic = torch.nn.Sigmoid()
        # self.logistic = torch.nn.Softmax(dim=1)


    def forward(self, drug_features, dis_features):
        drug_embedding = self.embedding_drug(drug_features)
        dis_embedding = self.embedding_dis(dis_features)
        drug_embedding = F.dropout(drug_embedding, 0.1)
        dis_embedding = F.dropout(dis_embedding, 0.1)
        dis_bias_mlp = self.dis_bias(torch.LongTensor(train_dis))
        drug_bias_mlp = self.drug_bias(torch.LongTensor(train_drug))
        vector = torch.cat([drug_embedding, dis_embedding + dis_bias_mlp +  drug_bias_mlp], dim=-1)
        for idx, _ in enumerate(range(len(self.fc_layers))):
            vector = self.fc_layers[idx](vector)
            vector = torch.nn.ReLU()(vector)
            vector = F.dropout(vector, 0.1)

        logits = self.affine_output(vector)
        rating = self.logistic(logits)
        return rating




# define the train function
def train_epocs_mlp(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):
    loss_arr=[]
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    model.train()
    for i in range(epochs):
        # users = torch.LongTensor(train[:,0])#.cuda()
        # items = torch.LongTensor(train[:,1])#.cuda()
        users = torch.Tensor(train_drug_features)
        items = torch.Tensor(train_dis_features)
        # print(users.size(), items.size())
        ratings = torch.FloatTensor(train.iloc[:,2].values)#.cuda()
        if unsqueeze:
            ratings = ratings.unsqueeze(1)
        y_hat = model(users, items)
        loss = F.mse_loss(y_hat, ratings)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        print(loss.item()) 
        loss_arr.append(loss.item())
    # test_loss(model, unsqueeze)
    print('save')
    # save the model
    torch.save(model.state_dict(), 'mlp_model.pt')
    plt.plot(loss_arr)
    plt.xlabel('epochs')
    plt.ylabel('MSE loss')
    plt.title('MLP')
    plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'MLP_MSE_Loss.png')

# build the mlp model
mlp_model = MLP(n_drugs, n_dis)#.cuda()



# train the model
#train_epocs_mlp(mlp_model, epochs=1000, lr=0.001, wd=1e-6, unsqueeze=True) #if use cuda the epochs could use 1000
train_epocs_mlp(mlp_model, epochs=100, lr=0.01, wd=1e-6, unsqueeze=True)

#Final Neural Matrix Factorization Model
class NeuMF(torch.nn.Module):
    def __init__(self, n_drugs, n_dis, latent_dim_mf=100, latent_dim_mlp=32, layers=[64,32,16,8]):
        super(NeuMF, self).__init__()

        # Part of GMF
        self.embedding_drug_mf = torch.nn.Embedding(num_embeddings=n_drugs, embedding_dim=latent_dim_mf)
        self.embedding_dis_mf = torch.nn.Embedding(num_embeddings=n_dis, embedding_dim=latent_dim_mf)
        self.embedding_drug_mf_bias = nn.Embedding(n_drugs, 1)
        self.embedding_dis_mf_bias = nn.Embedding(n_dis, 1)
        self.embedding_drug_mf_bias.weight.data.uniform_(-0.01,0.01)
        self.embedding_dis_mf_bias.weight.data.uniform_(-0.01,0.01)

        # Part of MLP
        self.feature_size = train_dis_features.shape[1]
        self.embedding_drug_mlp = torch.nn.Linear(self.feature_size, latent_dim_mlp)
        self.embedding_dis_mlp = torch.nn.Linear(self.feature_size, latent_dim_mlp)
        self.embedding_drug_mlp_bias = nn.Embedding(n_drugs, 1)
        self.embedding_dis_mlp_bias = nn.Embedding(n_dis, 1)
        self.embedding_drug_mlp_bias.weight.data.uniform_(-0.01,0.01)
        self.embedding_dis_mlp_bias.weight.data.uniform_(-0.01,0.01)
        self.fc_layers = torch.nn.ModuleList()
        for idx, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):
            self.fc_layers.append(torch.nn.Linear(in_size, out_size))

        self.affine_output = torch.nn.Linear(in_features=layers[-1] + latent_dim_mf, out_features=1)
        self.logistic = torch.nn.Sigmoid()
        # self.logistic = torch.nn.Softmax(dim=1)

    def forward(self, user_indices, item_indices, drug_features, dis_features):

        # Part of GMF
        drug_embedding_mf = self.embedding_drug_mf(user_indices)
        dis_embedding_mf = self.embedding_dis_mf(item_indices)
        drug_embedding_mf = F.dropout(drug_embedding_mf, 0.1)
        dis_embedding_mf = F.dropout(dis_embedding_mf, 0.1)
        dis_bias_mf = self.embedding_dis_mf_bias(item_indices)
        drug_bias_mf = self.embedding_drug_mf_bias(user_indices)
        mf_vector =torch.mul(drug_embedding_mf, dis_embedding_mf)
        mf_vector = mf_vector + dis_bias_mf+drug_bias_mf
        
        # Part of MLP
        drug_embedding_mlp = self.embedding_drug_mlp(drug_features)
        dis_embedding_mlp = self.embedding_dis_mlp(dis_features)
        drug_embedding_mlp = F.dropout(drug_embedding_mlp, 0.1)
        dis_embedding_mlp = F.dropout(dis_embedding_mlp, 0.1)
        dis_bias_mlp = self.embedding_dis_mlp_bias(item_indices)
        drug_bias_mlp = self.embedding_drug_mlp_bias(user_indices)
        mlp_vector = torch.cat([drug_embedding_mlp, dis_embedding_mlp + dis_bias_mlp +  drug_bias_mlp], dim=-1)
        for idx, _ in enumerate(range(len(self.fc_layers))):
            mlp_vector = self.fc_layers[idx](mlp_vector)
            mlp_vector = torch.nn.ReLU()(mlp_vector)
            mlp_vector = F.dropout(mlp_vector, 0.1)

        # Fusion of GMF and MLP
        vector = torch.cat([F.dropout(mlp_vector,0.1), F.dropout(mf_vector,0.1)], dim=-1)
        logits = self.affine_output(vector)
        rating = self.logistic(logits)
        return rating

    # load the wieght from GMF model and MLP model
    def load_pretrain_weights(self):
        
        # Part of GMF
        gmf_model = GMF(n_drugs,n_dis,latent_dim=100)#.cuda()
        gmf_model.load_state_dict(torch.load('gmf_model.pt'))
        self.embedding_drug_mf.weight.data = gmf_model.embedding_drug.weight.data
        self.embedding_dis_mf.weight.data = gmf_model.embedding_dis.weight.data

        # Part of MLP
        mlp_model = MLP(n_drugs,n_dis,latent_dim=32,layers=[64,32,16,8])#.cuda()
        mlp_model.load_state_dict(torch.load('mlp_model.pt'))
        self.embedding_drug_mlp.weight.data = mlp_model.embedding_drug.weight.data
        self.embedding_dis_mlp.weight.data = mlp_model.embedding_dis.weight.data        
        for idx in range(len(self.fc_layers)):
            self.fc_layers[idx].weight.data = mlp_model.fc_layers[idx].weight.data
        
        # Concatenate weights of the two models.
        self.affine_output.weight.data = 0.5 * torch.cat([mlp_model.affine_output.weight.data, gmf_model.affine_output.weight.data], dim=-1)
        self.affine_output.bias.data = 0.5 * (mlp_model.affine_output.bias.data + gmf_model.affine_output.bias.data)

def test_loss(model, val_drug, val_dis, val_drug_features, val_dis_features, true_label):
    model.eval()
    ratings = torch.FloatTensor(true_label)#.cuda()
    test_users = torch.LongTensor(val_drug)#.cuda()
    test_items = torch.LongTensor(val_dis)#.cuda()
    test_drug_features = torch.Tensor(val_drug_features)
    test_dis_features = torch.Tensor(val_dis_features)
    y_hat = model(test_users, test_items, test_drug_features, test_dis_features)
    # print(y_hat)
    return roc_auc_score(true_label, np.round(y_hat.detach().numpy())),accuracy_score(true_label, np.round(y_hat.detach().numpy())), precision_score(true_label, np.round(y_hat.detach().numpy())) , recall_score(true_label, np.round(y_hat.detach().numpy())) ,f1_score(true_label, np.round(y_hat.detach().numpy())) 
    # loss = F.mse_loss(torch.round(y_hat), ratings)
    # print("test loss %.3f " % loss.item())

# define the train function
def train_epocs_NeuMF(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)
    avg_auc = 0.0
    avg_acc = 0.0
    avg_prec = 0.0
    avg_recall = 0.0
    avg_f1 = 0.0
    print('test_auc, test_acc, test_prec, test_recall, test_f1')
    for train_ind, test_ind in kf.split(final_data):
        train_drug, train_dis, train_drug_features, train_dis_features = get_data(final_data.iloc[train_ind,:])
        val_drug, val_dis, val_drug_features, val_dis_features = get_data(final_data.iloc[test_ind,:])
        model = NeuMF(n_drugs, n_dis,layers=[64,32,16,8])#.cuda()
        model.load_pretrain_weights()
        model.train()
        loss_arr=[]
        for i in range(epochs):
            users = torch.LongTensor(train_drug)
            items = torch.LongTensor(train_dis)
            drugs = torch.Tensor(train_drug_features)
            dis = torch.Tensor(train_dis_features)
            ratings = torch.FloatTensor(final_data.iloc[train_ind,:].iloc[:,2].values)#.cuda()
            if unsqueeze:
                ratings = ratings.unsqueeze(1)
            y_hat = model(users, items, drugs,dis)
            loss = F.mse_loss(y_hat, ratings)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            # print(loss.item()) 
            loss_arr.append(loss.item())
        true_label = final_data.iloc[test_ind,:].iloc[:,2].values
        test_auc, test_acc, test_prec, test_recall, test_f1 = test_loss(model, val_drug, val_dis, val_drug_features, val_dis_features, true_label)
        avg_auc += test_auc
        avg_acc += test_acc
        avg_prec += test_prec
        avg_recall += test_recall
        avg_f1 += test_f1
        print(test_auc, test_acc, test_prec, test_recall, test_f1)
    print('Average')
    print(avg_auc/10,avg_acc/10,avg_prec/10,avg_recall/10,avg_f1/10)
    print('save')
    torch.save(NeuMF_model.state_dict(), 'NeuMF_model.pt')
    plt.plot(loss_arr)
    plt.xlabel('epochs')
    plt.ylabel('MSE loss')
    plt.title('NeuMF')
    plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'NeuMF_MSE_Loss.png')



# build the NeuMF model

NeuMF_model = NeuMF(n_drugs, n_dis,layers=[64,32,16,8])#.cuda()


# load the pre-training models of GMF and MLP
NeuMF_model.load_pretrain_weights()


# train the model
#train_epocs_NeuMF(NeuMF_model, epochs=1500, lr=0.0001, wd=1e-6, unsqueeze=True) #if use cuda, the epochs could use 1500
train_epocs_NeuMF(NeuMF_model, epochs=100, lr=0.01, wd=1e-6, unsqueeze=True)

"""**Final Result Compilation**"""

NeuMF_model.eval()
with torch.no_grad():
    val_drug, val_dis, val_drug_features, val_dis_features = get_data(test)
    test_users = torch.LongTensor(val_drug)#.cuda()
    test_items = torch.LongTensor(val_dis)#.cuda()
    test_drug_features = torch.Tensor(val_drug_features)
    test_dis_features = torch.Tensor(val_dis_features)
    users = torch.LongTensor(train_drug)
    items = torch.LongTensor(train_dis)
    drugs = torch.Tensor(train_drug_features)
    dis = torch.Tensor(train_dis_features)
    y_hat_NeuMF = NeuMF_model(test_users, test_items, test_drug_features, test_dis_features)
    y_hat_NeuMF_train = NeuMF_model(users, items, drugs, dis)
    print(y_hat_NeuMF)
    print(y_hat_NeuMF_train)

accuracy_score(np.round(y_hat_NeuMF.numpy()),test.iloc[:,2].values)

prec, recall, threshold = precision_recall_curve(val.iloc[:,2].values, y_hat_NeuMF.numpy())
lr_f1, lr_auc = f1_score(val.iloc[:,2].values, np.round(y_hat_NeuMF.numpy())), auc(recall, prec)
no_skill = len(val.iloc[:,2].values[val.iloc[:,2].values==1]) / len(val.iloc[:,2].values)
plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')
plt.plot(recall, prec, marker='.', label='NeuMF')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision Recall Curve')
plt.legend()
plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'precision_recall_curve.png')
print('F1 Score',lr_f1)
print('AUC', lr_auc)

fpr,tpr,_ = roc_curve(val.iloc[:,2].values, y_hat_NeuMF.numpy())
ns_probs = [0 for _ in range(len(val.iloc[:,2].values))]
ns_fpr, ns_tpr, _ = roc_curve(val.iloc[:,2].values, ns_probs)
plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
plt.plot(fpr, tpr, marker='.', label='NeuMF')
lr_auc = roc_auc_score(val.iloc[:,2].values, y_hat_NeuMF.numpy())
# axis labels
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'ROC_curve.png')
print('ROC AUC Score',lr_auc)

from sklearn.metrics import classification_report
classification_report(test.iloc[:,2].values, np.round(y_hat_NeuMF.numpy()),output_dict=True)



"""**Test Data Results**"""

NeuMF_model.eval()
with torch.no_grad():
    test_users = torch.LongTensor(test_drug)#.cuda()
    test_items = torch.LongTensor(test_dis)#.cuda()
    test_drug_features = torch.Tensor(test_drug_features)
    test_dis_features = torch.Tensor(test_dis_features)
    users = torch.LongTensor(train_drug)
    items = torch.LongTensor(train_dis)
    drugs = torch.Tensor(train_drug_features)
    dis = torch.Tensor(train_dis_features)
    y_hat_NeuMF = NeuMF_model(test_users, test_items, test_drug_features, test_dis_features)
    y_hat_NeuMF_train = NeuMF_model(users, items, drugs, dis)
    print(y_hat_NeuMF)
    print(y_hat_NeuMF_train)
    # rating_NeuMF = [element.item() for element in y_hat_NeuMF.flatten()]
    # df_NeuMF=pd.DataFrame({'user_id':val_drug,'item_id':val_dis,'rating':rating_NeuMF})
    # # df_NeuMF_sort=df_NeuMF.sort_values(by=['user_id','rating'],ascending=[True,False])
    # final_NeuMF=df_NeuMF_sort.groupby('user_id').head(10)
    # final_NeuMF.to_csv('final_NeuMF.csv',index=False)
    # final_NeuMF=final_NeuMF.drop(columns=['rating'])

from sklearn.metrics import accuracy_score
# accuracy_score(np.round(y_hat_NeuMF.numpy()),test.iloc[:,2].values), accuracy_score(np.round(y_hat_NeuMF_train.numpy()),train.iloc[:,2].values)
accuracy_score(np.round(y_hat_NeuMF.numpy()),test.iloc[:,2].values)

prec, recall, threshold = precision_recall_curve(test.iloc[:,2].values, y_hat_NeuMF.numpy())
lr_f1, lr_auc = f1_score(test.iloc[:,2].values, np.round(y_hat_NeuMF.numpy())), auc(recall, prec)
no_skill = len(test.iloc[:,2].values[test.iloc[:,2].values==1]) / len(test.iloc[:,2].values)
plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')
plt.plot(recall, prec, marker='.', label='NeuMF')
prec, recall, threshold = precision_recall_curve(test.iloc[:,2].values, test_hnet)
plt.plot(recall, prec, marker='.', label='HNet')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision Recall Curve')
plt.legend()
plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'precision_recall_curve_test.png')
print('F1 Score',lr_f1)
print('AUC', lr_auc)

fpr,tpr,_ = roc_curve(test.iloc[:,2].values, y_hat_NeuMF.numpy())
ns_probs = [0 for _ in range(len(test.iloc[:,2].values))]
ns_fpr, ns_tpr, _ = roc_curve(test.iloc[:,2].values, ns_probs)
plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
plt.plot(fpr, tpr, marker='.', label='NeuMF')
fpr,tpr,_ = roc_curve(test.iloc[:,2].values, test_hnet)
plt.plot(fpr, tpr, marker='.', label='HNet-DNN')
lr_auc = roc_auc_score(test.iloc[:,2].values, y_hat_NeuMF.numpy())
# axis labels
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'ROC_curve.png')
print('ROC AUC Score',lr_auc)

test_hnet = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/result/y-HNet-DNN.txt', header=None)
test_hnet = test_hnet.values.ravel()
accuracy_score(test_hnet,test.iloc[:,2].values)

test_hnet = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/result/probas1-HNet-DNN.txt', header=None)
test_hnet = test_hnet.values.ravel()
fpr,tpr,_ = roc_curve(test.iloc[:,2].values, test_hnet)
ns_probs = [0 for _ in range(len(test.iloc[:,2].values))]
ns_fpr, ns_tpr, _ = roc_curve(test.iloc[:,2].values, ns_probs)
plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
plt.plot(fpr, tpr, marker='.', label='HNet-DNN')
lr_auc = roc_auc_score(test.iloc[:,2].values, test_hnet)
# axis labels
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
# plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'ROC_curve.png')
print('ROC AUC Score',lr_auc)

#stats of evaluation metrics
res = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/results_neumf.txt', sep=' ', header=None)
res.columns = ['AUC', 'Acuracy', 'Precision', 'Recall', 'F1 Score']
res.describe()





"""##**PREDICT Dataset**"""

#Disease Features from heterogeneous network
dis_features = pd.read_csv('/content/drive/MyDrive/CF Dataset/PREDICT/disease_feature.txt', header=None)
dis_features = dis_features.iloc[:,1:].values
dis_features.shape

#Drug Features from heterogeneous network
drug_features = pd.read_csv('/content/drive/MyDrive/CF Dataset/PREDICT/drug_feature.txt', header=None)
drug_features = drug_features.iloc[:,1:].values
drug_features.shape

#Drug Disease Association Matrix
dda_mat = pd.read_csv('/content/drive/MyDrive/CF Dataset/PREDICT/DiDrAMat', sep = ' ', header=None)
dda_mat = dda_mat.values
dda_mat.shape

#Getting the train, validation and test datasets.
train = pd.read_csv('/content/drive/MyDrive/CF Dataset/PREDICT/train.txt', sep=' ',header=None)
# drug_features = pd.read_csv('/content/drive/MyDrive/CF Dataset/CDataset/drug_feature.txt', header=None)
val = pd.read_csv('/content/drive/MyDrive/CF Dataset/PREDICT/valid.txt', sep=' ',header=None)
test = pd.read_csv('/content/drive/MyDrive/CF Dataset/PREDICT/test.txt', sep=' ',header=None)
final_data = pd.concat([train,val],ignore_index=True, sort=False)
# train.head(),val.head(),test.head()
final_data.head(),final_data.shape

#Drug and Disease Features corresponding to their IDs
drug_f = dict()
with open('/content/drive/MyDrive/CF Dataset/PREDICT/drug_feature.txt', 'r') as f:
    for line in f:
        drug_id, fp = line.strip().split()
        fp = np.array(fp.split(','), dtype='float32')
        drug_f[drug_id] = fp

disease_f = dict()
with open('/content/drive/MyDrive/CF Dataset/PREDICT/disease_feature.txt', 'r') as f:
    for line in f:
        disease_id, md = line.strip().split()
        md = np.array(md.split(','), dtype='float32')
        disease_f[disease_id] = md

#Giving a code to every drug and disease
drug_code={}
dis_code={}
i=0
for drug in drug_f.keys():
  drug_code[drug]=i
  i+=1
i=0
for dis in disease_f.keys():
  dis_code[dis]=i
  i+=1

n_drugs = np.unique(train.iloc[:,0].values).shape[0]
n_dis = np.unique(train.iloc[:,1].values).shape[0]
print(n_drugs, n_dis)
def get_data(data):
  """
  Function that returns all 4 components of data
  """
  train_drug = np.array([drug_code[d] for d in data.iloc[:,0].values])
  train_dis = np.array([dis_code[d] for d in data.iloc[:,1].values])
  train_drug_features = np.array([drug_f[d] for d in data.iloc[:,0].values])
  train_dis_features = np.array([disease_f[d] for d in data.iloc[:,1].values])
  return train_drug, train_dis, train_drug_features, train_dis_features
train_drug, train_dis, train_drug_features, train_dis_features = get_data(train)

#10 Fold CV
from sklearn.model_selection import KFold
kf = KFold(n_splits=10)

gmf_model = GMF(n_drugs, n_dis)
train_epocs_gmf(gmf_model, epochs=100, lr=0.01, wd=1e-6, unsqueeze=True)

# build the mlp model
mlp_model = MLP(n_drugs, n_dis)#.cuda()



# train the model
#train_epocs_mlp(mlp_model, epochs=1000, lr=0.001, wd=1e-6, unsqueeze=True) #if use cuda the epochs could use 1000
train_epocs_mlp(mlp_model, epochs=100, lr=0.01, wd=1e-6, unsqueeze=True)

NeuMF_model = NeuMF(n_drugs, n_dis,layers=[64,32,16,8])#.cuda()


# load the pre-training models of GMF and MLP
NeuMF_model.load_pretrain_weights()


# train the model
#train_epocs_NeuMF(NeuMF_model, epochs=1500, lr=0.0001, wd=1e-6, unsqueeze=True) #if use cuda, the epochs could use 1500
train_epocs_NeuMF(NeuMF_model, epochs=100, lr=0.01, wd=1e-6, unsqueeze=True)

NeuMF_model.eval()
test_drug, test_dis, test_drug_features, test_dis_features = get_data(test)
with torch.no_grad():
    test_users = torch.LongTensor(test_drug)#.cuda()
    test_items = torch.LongTensor(test_dis)#.cuda()
    test_drug_features = torch.Tensor(test_drug_features)
    test_dis_features = torch.Tensor(test_dis_features)
    users = torch.LongTensor(train_drug)
    items = torch.LongTensor(train_dis)
    drugs = torch.Tensor(train_drug_features)
    dis = torch.Tensor(train_dis_features)
    y_hat_NeuMF = NeuMF_model(test_users, test_items, test_drug_features, test_dis_features)
    y_hat_NeuMF_train = NeuMF_model(users, items, drugs, dis)
    print(y_hat_NeuMF)
    print(y_hat_NeuMF_train)
    # rating_NeuMF = [element.item() for element in y_hat_NeuMF.flatten()]
    # df_NeuMF=pd.DataFrame({'user_id':val_drug,'item_id':val_dis,'rating':rating_NeuMF})
    # # df_NeuMF_sort=df_NeuMF.sort_values(by=['user_id','rating'],ascending=[True,False])
    # final_NeuMF=df_NeuMF_sort.groupby('user_id').head(10)
    # final_NeuMF.to_csv('final_NeuMF.csv',index=False)
    # final_NeuMF=final_NeuMF.drop(columns=['rating'])

from sklearn.metrics import accuracy_score
# accuracy_score(np.round(y_hat_NeuMF.numpy()),test.iloc[:,2].values), accuracy_score(np.round(y_hat_NeuMF_train.numpy()),train.iloc[:,2].values)
accuracy_score(np.round(y_hat_NeuMF.numpy()),test.iloc[:,2].values)

prec, recall, threshold = precision_recall_curve(test.iloc[:,2].values, y_hat_NeuMF.numpy())
lr_f1, lr_auc = f1_score(test.iloc[:,2].values, np.round(y_hat_NeuMF.numpy())), auc(recall, prec)
no_skill = len(test.iloc[:,2].values[test.iloc[:,2].values==1]) / len(test.iloc[:,2].values)
plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')
plt.plot(recall, prec, marker='.', label='NeuMF')
# prec, recall, threshold = precision_recall_curve(test.iloc[:,2].values, test_hnet)
# plt.plot(recall, prec, marker='.', label='HNet')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision Recall Curve')
plt.legend()
plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'precision_recall_curve_test.png')
print('F1 Score',lr_f1)
print('AUC', lr_auc)

fpr,tpr,_ = roc_curve(test.iloc[:,2].values, y_hat_NeuMF.numpy())
ns_probs = [0 for _ in range(len(test.iloc[:,2].values))]
ns_fpr, ns_tpr, _ = roc_curve(test.iloc[:,2].values, ns_probs)
plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
plt.plot(fpr, tpr, marker='.', label='NeuMF')
# fpr,tpr,_ = roc_curve(test.iloc[:,2].values, test_hnet)
# plt.plot(fpr, tpr, marker='.', label='HNet-DNN')
lr_auc = roc_auc_score(test.iloc[:,2].values, y_hat_NeuMF.numpy())
# axis labels
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.savefig('/content/drive/MyDrive/CF Dataset/Project Plots/'+'ROC_curve.png')
print('ROC AUC Score',lr_auc)



